{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_vPEDQaNW1jY",
        "outputId": "d269f655-1a0b-49ee-8e26-64af894d7277"
      },
      "outputs": [],
      "source": [
        "!pip install --force-reinstall transformers datasets evaluate scikit-learn accelerate --no-build-isolation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "15NjoCNMaIe8",
        "outputId": "b21d7e76-1385-469a-93d0-50a29b02f850"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qg6lCDKtuofy",
        "outputId": "31ce4706-9870-41c9-c3aa-b71b94995afd"
      },
      "outputs": [],
      "source": [
        "!pip uninstall -y torch torchvision torchaudio\n",
        "!pip install torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip install causal-conv1d==1.4.0 && pip install mamba-ssm==2.2.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PlPrUEYbbMA3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from transformers import AutoModel, AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMM30fDJcxKY",
        "outputId": "964200e7-9332-4214-dcb2-dd8496083c64"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"clinvar_sequence_disease_clean.csv\")\n",
        "\n",
        "print(\"Sample rows:\")\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVD3eDSQbY0E",
        "outputId": "8f19c8cf-3bdd-4de0-ccc2-590885f80101"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "all_labels = [d for x in df['disease_labels'] for d in x.split(\",\")]\n",
        "label_counts = Counter(all_labels)\n",
        "\n",
        "top_labels = [d for d, _ in label_counts.most_common(500)]\n",
        "label2id = {d:i for i,d in enumerate(top_labels)}\n",
        "id2label = {i:d for d,i in label2id.items()}\n",
        "num_labels = len(top_labels)\n",
        "\n",
        "print(\"Number of diseases kept:\", num_labels)\n",
        "print(\"Most common ones:\", list(label2id.keys())[:10])\n",
        "\n",
        "def encode_labels(label_str):\n",
        "    y = [0]*num_labels\n",
        "    for d in label_str.split(\",\"):\n",
        "        if d in label2id:  \n",
        "            y[label2id[d]] = 1\n",
        "    return y\n",
        "\n",
        "df[\"label_vec\"] = df[\"disease_labels\"].apply(encode_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KICdoD7Jd4e-",
        "outputId": "399b9afa-8534-4777-c783-b550ccd1b739"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df_small = df.sample(n=5000, random_state=42)\n",
        "\n",
        "train_df, temp_df = train_test_split(df_small, test_size=0.2, random_state=42)\n",
        "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
        "\n",
        "print(\"Train size:\", len(train_df))\n",
        "print(\"Validation size:\", len(val_df))\n",
        "print(\"Test size:\", len(test_df))\n",
        "print(train_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IrwTZkercHB1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "DNA_VOCAB = {\"A\": 0, \"C\": 1, \"G\": 2, \"T\": 3, \"N\": 4}\n",
        "\n",
        "def tokenize_dna(sequence, max_len):\n",
        "    ids = [DNA_VOCAB.get(base, 4) for base in sequence]\n",
        "    \n",
        "    if len(ids) < max_len:\n",
        "        ids += [4] * (max_len - len(ids))\n",
        "    else:\n",
        "        ids = ids[:max_len]\n",
        "    return torch.tensor(ids, dtype=torch.long)\n",
        "\n",
        "def create_attention_mask(input_ids):\n",
        "    return (input_ids != 4).long()\n",
        "\n",
        "class DNADataset(Dataset):\n",
        "    def __init__(self, sequences, labels, max_len=512):\n",
        "        self.sequences = sequences\n",
        "        self.labels = labels\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        seq = self.sequences[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        input_ids = tokenize_dna(seq, self.max_len)\n",
        "        attention_mask = create_attention_mask(input_ids)\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": input_ids,\n",
        "            \"attention_mask\": attention_mask,\n",
        "            \"labels\": torch.tensor(label, dtype=torch.float)\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dd_oW72icJP_",
        "outputId": "7e8e5caf-b33c-441f-a909-03e384badf3a"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model_name = \"kuleshov-group/caduceus-ps_seqlen-131k_d_model-256_n_layer-16\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "backbone = AutoModel.from_pretrained(model_name).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lZRtz8Cee1R",
        "outputId": "509c76ef-a09b-4a16-ed1d-7263bd569a64"
      },
      "outputs": [],
      "source": [
        "MAX_LEN = 512\n",
        "\n",
        "train_ds = DNADataset(train_df[\"sequence\"].tolist(),\n",
        "                      train_df[\"label_vec\"].tolist(),\n",
        "                      max_len=MAX_LEN)\n",
        "\n",
        "val_ds = DNADataset(val_df[\"sequence\"].tolist(),\n",
        "                    val_df[\"label_vec\"].tolist(),\n",
        "                    max_len=MAX_LEN)\n",
        "\n",
        "test_ds = DNADataset(test_df[\"sequence\"].tolist(),\n",
        "                     test_df[\"label_vec\"].tolist(),\n",
        "                     max_len=MAX_LEN)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=2, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=2)\n",
        "test_loader = DataLoader(test_ds, batch_size=2)\n",
        "\n",
        "sample = train_ds[0]\n",
        "print(\"Keys in dataset sample:\", sample.keys())\n",
        "print(\"Input IDs:\", sample[\"input_ids\"])\n",
        "print(\"Attention mask:\", sample[\"attention_mask\"])\n",
        "print(\"Labels:\", sample[\"labels\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VEvMnKSncPqz"
      },
      "outputs": [],
      "source": [
        "class DiseaseClassifier(nn.Module):\n",
        "    def __init__(self, backbone, hidden_size, num_labels):\n",
        "        super().__init__()\n",
        "        self.backbone = backbone\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(256, num_labels)\n",
        "        )\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        outputs = self.backbone(input_ids)\n",
        "\n",
        "        hidden = (\n",
        "            outputs.last_hidden_state\n",
        "            if hasattr(outputs, \"last_hidden_state\")\n",
        "            else outputs\n",
        "        )\n",
        "\n",
        "        pooled = hidden.mean(dim=1)\n",
        "        return self.classifier(pooled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yt5R7WOcesd0"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "import numpy as np\n",
        "\n",
        "def evaluate(loader):\n",
        "    model.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            ids = batch[\"input_ids\"].to(device)\n",
        "            mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            logits = model(ids, mask)\n",
        "            probs = torch.sigmoid(logits).cpu().numpy()\n",
        "            all_preds.append(probs)\n",
        "            all_labels.append(labels.cpu().numpy())\n",
        "\n",
        "    all_preds = np.vstack(all_preds)\n",
        "    all_labels = np.vstack(all_labels)\n",
        "\n",
        "    bin_preds = (all_preds >= 0.5).astype(int)\n",
        "\n",
        "    metrics = {}\n",
        "    metrics[\"accuracy\"]  = (bin_preds == all_labels).mean()\n",
        "    metrics[\"f1_macro\"]  = f1_score(all_labels, bin_preds, average=\"macro\", zero_division=0)\n",
        "    metrics[\"f1_micro\"]  = f1_score(all_labels, bin_preds, average=\"micro\", zero_division=0)\n",
        "    metrics[\"precision\"] = precision_score(all_labels, bin_preds, average=\"macro\", zero_division=0)\n",
        "    metrics[\"recall\"]    = recall_score(all_labels, bin_preds, average=\"macro\", zero_division=0)\n",
        "\n",
        "    return metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "UmoGxt6EewYE",
        "outputId": "591a4421-5b62-4732-bb9c-bbdf7ec6b5de"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.optim import AdamW\n",
        "import torch.nn as nn\n",
        "\n",
        "hidden_size = backbone.config.d_model\n",
        "model = DiseaseClassifier(backbone, hidden_size, num_labels).to(device)\n",
        "\n",
        "all_labels = []\n",
        "\n",
        "for batch in train_loader:\n",
        "    all_labels.append(batch[\"labels\"])\n",
        "all_labels = torch.cat(all_labels, dim=0).float()\n",
        "\n",
        "pos_counts = all_labels.sum(dim=0)\n",
        "neg_counts = all_labels.size(0) - pos_counts\n",
        "\n",
        "pos_weight = neg_counts / (pos_counts + 1e-5)\n",
        "pos_weight = pos_weight.to(device)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "optimizer = AdamW(model.parameters(), lr=1e-4)\n",
        "\n",
        "for epoch in range(3):\n",
        "    model.train()\n",
        "    for batch in train_loader:\n",
        "        ids = batch[\"input_ids\"].to(device)\n",
        "        mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device).float()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(input_ids=ids, attention_mask=mask)\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    val_metrics = evaluate(val_loader)\n",
        "    print(f\"Epoch {epoch+1}: {val_metrics}\")\n",
        "\n",
        "    batch = next(iter(val_loader))\n",
        "    ids, mask, labels = batch[\"input_ids\"].to(device), batch[\"attention_mask\"].to(device), batch[\"labels\"].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = model(input_ids=ids, attention_mask=mask)\n",
        "        probs = torch.sigmoid(logits)\n",
        "        preds = (probs > 0.5).int()\n",
        "\n",
        "    print(\"Predictions:\", preds[:5].tolist())\n",
        "    print(\"Labels:\", labels[:5].tolist())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61sXQ6k_e0rl"
      },
      "outputs": [],
      "source": [
        "test_auc = evaluate(test_loader)\n",
        "print(\"Final Test AUROC:\", test_auc)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
