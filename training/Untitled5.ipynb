{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3aUggkjhnWTv"
      },
      "outputs": [],
      "source": [
        "!pip install --force-reinstall transformers datasets evaluate scikit-learn accelerate --no-build-isolation\n",
        "!pip uninstall -y torch torchvision torchaudio\n",
        "!pip install torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip install causal-conv1d==1.4.0 && pip install mamba-ssm==2.2.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBxAINamqhUz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score\n",
        "from transformers import AutoModel, AutoTokenizer, get_linear_schedule_with_warmup\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "itMwTVaLqsCP"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XqVxXeEYqpli"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"clinvar_sequence_disease_clean.csv\")\n",
        "print(\"Dataset shape:\", df.shape)\n",
        "print(\"Columns:\", df.columns.tolist())\n",
        "print(\"Sample rows:\")\n",
        "\n",
        "print(\"Test dataset shape:\", df.shape)\n",
        "\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYypLmy5rSCX"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "all_labels = [d for x in df['disease_labels'] for d in x.split(\",\")]\n",
        "label_counts = Counter(all_labels)\n",
        "\n",
        "top_labels = [d for d, _ in label_counts.most_common(100)]\n",
        "label2id = {d: i for i, d in enumerate(top_labels)}\n",
        "id2label = {i: d for d, i in label2id.items()}\n",
        "num_labels = len(top_labels)\n",
        "\n",
        "print(\"Number of diseases kept:\", num_labels)\n",
        "print(\"Most common ones:\", list(label2id.keys())[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0pxoqcurado"
      },
      "outputs": [],
      "source": [
        "def encode_labels(label_str):\n",
        "    y = [0] * num_labels\n",
        "    for d in label_str.split(\",\"):\n",
        "        if d in label2id:\n",
        "            y[label2id[d]] = 1\n",
        "    return y\n",
        "\n",
        "df[\"label_vec\"] = df[\"disease_labels\"].apply(encode_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "klv8e_z-rdix"
      },
      "outputs": [],
      "source": [
        "train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42, stratify=None)\n",
        "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42, stratify=None)\n",
        "\n",
        "print(f\"Train size: {len(train_df)}\")\n",
        "print(f\"Val size: {len(val_df)}\")\n",
        "print(f\"Test size: {len(test_df)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "41vuCN_1rmsH"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "model_name = \"kuleshov-group/caduceus-ps_seqlen-131k_d_model-256_n_layer-16\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "backbone = AutoModel.from_pretrained(model_name).to(device)\n",
        "\n",
        "print(f\"Backbone hidden size: {backbone.config.d_model}\")\n",
        "print(f\"Backbone vocab size: {backbone.config.vocab_size}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "180O_GJ1tei-"
      },
      "outputs": [],
      "source": [
        "class DNADataset(Dataset):\n",
        "    def __init__(self, sequences, labels, tokenizer, max_len=512):\n",
        "        self.sequences = sequences\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        seq = self.sequences[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if len(seq) > self.max_len:\n",
        "            seq = seq[:self.max_len]\n",
        "\n",
        "        try:\n",
        "            encoding = self.tokenizer(\n",
        "                seq,\n",
        "                truncation=True,\n",
        "                padding='max_length',\n",
        "                max_length=self.max_len,\n",
        "                return_tensors='pt'\n",
        "            )\n",
        "\n",
        "            input_ids = encoding['input_ids'].squeeze()\n",
        "\n",
        "            if 'attention_mask' in encoding:\n",
        "                attention_mask = encoding['attention_mask'].squeeze()\n",
        "            else:\n",
        "                pad_token_id = getattr(self.tokenizer, 'pad_token_id', 0)\n",
        "                attention_mask = (input_ids != pad_token_id).long()\n",
        "\n",
        "        except Exception as e:\n",
        "            DNA_VOCAB = {\"A\": 0, \"C\": 1, \"G\": 2, \"T\": 3, \"N\": 4}\n",
        "\n",
        "            token_ids = [DNA_VOCAB.get(char.upper(), 4) for char in seq]\n",
        "\n",
        "            if len(token_ids) < self.max_len:\n",
        "                original_len = len(token_ids)\n",
        "                token_ids += [4] * (self.max_len - len(token_ids))\n",
        "                attention_mask = [1] * original_len + [0] * (self.max_len - original_len)\n",
        "            else:\n",
        "                token_ids = token_ids[:self.max_len]\n",
        "                attention_mask = [1] * self.max_len\n",
        "\n",
        "            input_ids = torch.tensor(token_ids, dtype=torch.long)\n",
        "            attention_mask = torch.tensor(attention_mask, dtype=torch.long)\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": input_ids,\n",
        "            \"attention_mask\": attention_mask,\n",
        "            \"labels\": torch.tensor(label, dtype=torch.float)\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y-zkf-vKtlbX"
      },
      "outputs": [],
      "source": [
        "MAX_LEN = 512\n",
        "BATCH_SIZE = 8\n",
        "\n",
        "train_ds = DNADataset(train_df[\"sequence\"].tolist(), train_df[\"label_vec\"].tolist(), tokenizer, MAX_LEN)\n",
        "val_ds = DNADataset(val_df[\"sequence\"].tolist(), val_df[\"label_vec\"].tolist(), tokenizer, MAX_LEN)\n",
        "test_ds = DNADataset(test_df[\"sequence\"].tolist(), test_df[\"label_vec\"].tolist(), tokenizer, MAX_LEN)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE)\n",
        "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7_0MnFZ4u_cf"
      },
      "outputs": [],
      "source": [
        "print(\"\\nTesting backbone model compatibility...\")\n",
        "sample_batch = next(iter(train_loader))\n",
        "ids = sample_batch[\"input_ids\"][:2].to(device)\n",
        "mask = sample_batch[\"attention_mask\"][:2].to(device)\n",
        "\n",
        "backbone_call_method = None\n",
        "try:\n",
        "    print(\"Testing backbone(input_ids=ids, attention_mask=mask)...\")\n",
        "    outputs = backbone(input_ids=ids, attention_mask=mask)\n",
        "    backbone_call_method = \"keyword_args\"\n",
        "    print(\"Keyword arguments work!\")\n",
        "except Exception as e:\n",
        "    print(f\"Keyword args failed: {e}\")\n",
        "\n",
        "    try:\n",
        "        print(\"Testing backbone(ids)...\")\n",
        "        outputs = backbone(ids)\n",
        "        backbone_call_method = \"input_ids_only\"\n",
        "        print(\"Input IDs only works!\")\n",
        "    except Exception as e:\n",
        "        print(f\"Input IDs only failed: {e}\")\n",
        "\n",
        "        try:\n",
        "            print(\"Testing backbone(ids, mask)...\")\n",
        "            outputs = backbone(ids, mask)\n",
        "            backbone_call_method = \"positional_args\"\n",
        "            print(\"Positional arguments work!\")\n",
        "        except Exception as e:\n",
        "            print(f\"All methods failed: {e}\")\n",
        "            raise\n",
        "\n",
        "print(\"\\nDetecting actual backbone output dimensions...\")\n",
        "with torch.no_grad():\n",
        "    if backbone_call_method == \"keyword_args\":\n",
        "        outputs = backbone(input_ids=ids, attention_mask=mask)\n",
        "    elif backbone_call_method == \"input_ids_only\":\n",
        "        outputs = backbone(ids)\n",
        "    else:\n",
        "        outputs = backbone(ids, mask)\n",
        "\n",
        "    if hasattr(outputs, 'last_hidden_state'):\n",
        "        hidden = outputs.last_hidden_state\n",
        "    elif isinstance(outputs, tuple):\n",
        "        hidden = outputs[0]\n",
        "    else:\n",
        "        hidden = outputs\n",
        "\n",
        "    # Pool to get final dimension\n",
        "    pooled = hidden.mean(dim=1)  # Average pooling\n",
        "    actual_hidden_size = pooled.shape[-1]\n",
        "\n",
        "print(f\"Config says d_model: {backbone.config.d_model}\")\n",
        "print(f\"Actual output size: {actual_hidden_size}\")\n",
        "print(f\"Hidden state shape: {hidden.shape}\")\n",
        "print(f\"Pooled shape: {pooled.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gn34P5yMtpCs"
      },
      "outputs": [],
      "source": [
        "class DiseaseClassifier(nn.Module):\n",
        "    def __init__(self, backbone, num_labels, actual_hidden_size, backbone_call_method, dropout_rate=0.3):\n",
        "        super().__init__()\n",
        "        self.backbone = backbone\n",
        "        self.backbone_call_method = backbone_call_method\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "        # Use the ACTUAL hidden size, not config\n",
        "        hidden_size = actual_hidden_size\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_size, hidden_size // 2),\n",
        "            nn.LayerNorm(hidden_size // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(hidden_size // 2, hidden_size // 4),\n",
        "            nn.LayerNorm(hidden_size // 4),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(hidden_size // 4, num_labels)\n",
        "        )\n",
        "\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        for module in self.classifier:\n",
        "            if isinstance(module, nn.Linear):\n",
        "                torch.nn.init.xavier_normal_(module.weight)\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        if self.backbone_call_method == \"keyword_args\":\n",
        "            outputs = self.backbone(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        elif self.backbone_call_method == \"input_ids_only\":\n",
        "            outputs = self.backbone(input_ids)\n",
        "        else:\n",
        "            outputs = self.backbone(input_ids, attention_mask)\n",
        "\n",
        "        if hasattr(outputs, 'last_hidden_state'):\n",
        "            hidden = outputs.last_hidden_state\n",
        "        elif isinstance(outputs, tuple):\n",
        "            hidden = outputs[0]\n",
        "        else:\n",
        "            hidden = outputs\n",
        "\n",
        "        if attention_mask is not None and self.backbone_call_method != \"input_ids_only\":\n",
        "            mask_expanded = attention_mask.unsqueeze(-1).expand(hidden.size()).float()\n",
        "            sum_hidden = torch.sum(hidden * mask_expanded, dim=1)\n",
        "            sum_mask = torch.clamp(mask_expanded.sum(dim=1), min=1e-9)\n",
        "            pooled = sum_hidden / sum_mask\n",
        "        else:\n",
        "            pooled = hidden.mean(dim=1)\n",
        "\n",
        "        pooled = self.dropout(pooled)\n",
        "        logits = self.classifier(pooled)\n",
        "\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rkDba3rSx7er"
      },
      "outputs": [],
      "source": [
        "model = DiseaseClassifier(backbone, num_labels, actual_hidden_size, backbone_call_method).to(device)\n",
        "print(f\"\\nFixed model created with actual hidden size: {actual_hidden_size}\")\n",
        "print(f\"Model parameters: {sum(p.numel() for p in model.parameters())}\")\n",
        "\n",
        "try:\n",
        "    with torch.no_grad():\n",
        "        test_logits = model(ids, mask)\n",
        "        print(f\"SUCCESS! Output shape: {test_logits.shape}\")\n",
        "        print(f\"Expected shape: ({ids.shape[0]}, {num_labels})\")\n",
        "except Exception as e:\n",
        "    print(f\"Model forward pass failed: {e}\")\n",
        "    raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bxH6pPE-ttEQ"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, loader, device):\n",
        "    model.eval()\n",
        "    all_probs, all_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(loader, desc=\"Evaluating\"):\n",
        "            ids = batch[\"input_ids\"].to(device)\n",
        "            mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            logits = model(ids, mask)\n",
        "            probs = torch.sigmoid(logits).cpu().numpy()\n",
        "\n",
        "            all_probs.append(probs)\n",
        "            all_labels.append(labels.cpu().numpy())\n",
        "\n",
        "    all_probs = np.vstack(all_probs)\n",
        "    all_labels = np.vstack(all_labels)\n",
        "\n",
        "    best_f1 = 0\n",
        "    best_threshold = 0.5\n",
        "\n",
        "    for thresh in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]:\n",
        "        bin_preds = (all_probs >= thresh).astype(int)\n",
        "        f1 = f1_score(all_labels, bin_preds, average=\"micro\", zero_division=0)\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_threshold = thresh\n",
        "\n",
        "    bin_preds = (all_probs >= best_threshold).astype(int)\n",
        "\n",
        "    return {\n",
        "        \"threshold\": best_threshold,\n",
        "        \"f1_micro\": f1_score(all_labels, bin_preds, average=\"micro\", zero_division=0),\n",
        "        \"f1_macro\": f1_score(all_labels, bin_preds, average=\"macro\", zero_division=0),\n",
        "        \"precision\": precision_score(all_labels, bin_preds, average=\"macro\", zero_division=0),\n",
        "        \"recall\": recall_score(all_labels, bin_preds, average=\"macro\", zero_division=0),\n",
        "        \"accuracy\": (bin_preds == all_labels).mean()\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IIvwkNYptur9"
      },
      "outputs": [],
      "source": [
        "all_labels = []\n",
        "for batch in train_loader:\n",
        "    all_labels.append(batch[\"labels\"])\n",
        "all_labels = torch.cat(all_labels, dim=0).float()\n",
        "\n",
        "pos_counts = all_labels.sum(dim=0)\n",
        "neg_counts = all_labels.size(0) - pos_counts\n",
        "pos_weight = torch.clamp(neg_counts / (pos_counts + 1e-5), min=0.1, max=10.0).to(device)\n",
        "\n",
        "print(f\"Positive weights range: {pos_weight.min():.2f} - {pos_weight.max():.2f}\")\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-4, weight_decay=0.01)\n",
        "\n",
        "num_epochs = 10\n",
        "total_steps = len(train_loader) * num_epochs\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=int(0.1 * total_steps),\n",
        "    num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "print(f\"\\nTraining setup:\")\n",
        "print(f\"  Epochs: {num_epochs}\")\n",
        "print(f\"  Steps per epoch: {len(train_loader)}\")\n",
        "print(f\"  Total steps: {total_steps}\")\n",
        "print(f\"  Backbone call method: {backbone_call_method}\")\n",
        "print(f\"  Actual hidden size: {actual_hidden_size}\")\n",
        "\n",
        "best_val_f1 = 0\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STARTING TRAINING - ALL ISSUES FIXED!\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    num_batches = 0\n",
        "\n",
        "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "\n",
        "    for batch in progress_bar:\n",
        "        ids = batch[\"input_ids\"].to(device)\n",
        "        mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device).float()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        logits = model(ids, mask)\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        num_batches += 1\n",
        "\n",
        "        progress_bar.set_postfix({\n",
        "            'loss': f'{total_loss/num_batches:.4f}',\n",
        "            'lr': f'{scheduler.get_last_lr()[0]:.2e}'\n",
        "        })\n",
        "\n",
        "    print(f\"\\nEpoch {epoch+1} - Average Loss: {total_loss/num_batches:.4f}\")\n",
        "\n",
        "    val_metrics = evaluate(model, val_loader, device)\n",
        "    print(f\"Validation: {val_metrics}\")\n",
        "\n",
        "    if val_metrics[\"f1_micro\"] > best_val_f1:\n",
        "        best_val_f1 = val_metrics[\"f1_micro\"]\n",
        "        torch.save(model.state_dict(), 'best_model.pth')\n",
        "        print(f\"New best F1: {best_val_f1:.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"FINAL RESULTS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "test_metrics = evaluate(model, test_loader, device)\n",
        "print(f\"Test metrics: {test_metrics}\")\n",
        "print(f\"F1:     {test_metrics['f1_micro']:.1%}\")\n",
        "\n",
        "print(\"=\"*60)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
